{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11959,"sourceType":"datasetVersion","datasetId":8544}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#import necessary libraries\nimport os\nimport copy\nimport torch\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import models\nfrom sklearn.utils import shuffle\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager\nfrom collections import OrderedDict","metadata":{"papermill":{"duration":4.602022,"end_time":"2023-11-07T12:24:29.018688","exception":false,"start_time":"2023-11-07T12:24:24.416666","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T13:54:00.985657Z","iopub.execute_input":"2024-04-05T13:54:00.985947Z","iopub.status.idle":"2024-04-05T13:54:06.161341Z","shell.execute_reply.started":"2024-04-05T13:54:00.985921Z","shell.execute_reply":"2024-04-05T13:54:06.160313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice\n\nimport os\nprint(os.getcwd())","metadata":{"papermill":{"duration":0.080239,"end_time":"2023-11-07T12:24:29.173128","exception":false,"start_time":"2023-11-07T12:24:29.092889","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T13:54:15.420162Z","iopub.execute_input":"2024-04-05T13:54:15.421118Z","iopub.status.idle":"2024-04-05T13:54:15.486454Z","shell.execute_reply.started":"2024-04-05T13:54:15.421082Z","shell.execute_reply":"2024-04-05T13:54:15.485478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if \"food-101\" in os.listdir():\n    print(\"Dataset already exists\")\nelse:\n    print(\"Downloading the data...\")\n    !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n    print(\"Dataset downloaded!\")\n    print(\"Extracting data..\")\n    !tar xzvf food-101.tar.gz > /dev/null 2>&1\n    print(\"Extraction done!\")","metadata":{"papermill":{"duration":502.551636,"end_time":"2023-11-07T12:32:51.836856","exception":false,"start_time":"2023-11-07T12:24:29.28522","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T13:54:21.716009Z","iopub.execute_input":"2024-04-05T13:54:21.716902Z","iopub.status.idle":"2024-04-05T13:58:16.088856Z","shell.execute_reply.started":"2024-04-05T13:54:21.716866Z","shell.execute_reply":"2024-04-05T13:58:16.087581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = open(\"./food-101/meta/classes.txt\", 'r').read().splitlines()\nclasses_21 = classes[:20] + ['other']\nclasses_21, len(classes_21)","metadata":{"papermill":{"duration":0.164934,"end_time":"2023-11-07T12:32:52.457696","exception":false,"start_time":"2023-11-07T12:32:52.292762","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T13:59:03.314032Z","iopub.execute_input":"2024-04-05T13:59:03.314458Z","iopub.status.idle":"2024-04-05T13:59:03.324974Z","shell.execute_reply.started":"2024-04-05T13:59:03.314411Z","shell.execute_reply":"2024-04-05T13:59:03.324048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!echo \"Testing images\"\n!head -n 5 ./food-101/meta/test.txt\n!echo -e \"\\nTraining images\"\n!head -n 5 ./food-101/meta/train.txt | head -n 5","metadata":{"papermill":{"duration":4.03086,"end_time":"2023-11-07T12:32:57.530548","exception":false,"start_time":"2023-11-07T12:32:53.499688","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T13:59:08.17174Z","iopub.execute_input":"2024-04-05T13:59:08.172098Z","iopub.status.idle":"2024-04-05T13:59:11.956477Z","shell.execute_reply.started":"2024-04-05T13:59:08.17207Z","shell.execute_reply":"2024-04-05T13:59:11.955566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prep_df(path: str) -> pd.DataFrame:\n    array = open(path, 'r').read().splitlines()\n\n    # Getting the full path for the images\n    img_path = \"./food-101/images/\"\n    full_path = [img_path + img + \".jpg\" for img in array]\n\n    # Splitting the image index from the label\n    imgs = []\n    for img in array:\n        img = img.split('/')\n\n        imgs.append(img)\n\n    imgs = np.array(imgs)\n    # Converting the array to a data frame\n    imgs = pd.DataFrame(imgs[:,0], imgs[:,1], columns=['label'])\n    # Adding the full path to the data frame\n    imgs['path'] = full_path\n\n    # Randomly shuffling the order to the data in the dataframe\n    imgs = shuffle(imgs)\n\n    return imgs","metadata":{"papermill":{"duration":0.164566,"end_time":"2023-11-07T12:32:58.483896","exception":false,"start_time":"2023-11-07T12:32:58.31933","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T13:59:21.983649Z","iopub.execute_input":"2024-04-05T13:59:21.984006Z","iopub.status.idle":"2024-04-05T13:59:21.990883Z","shell.execute_reply.started":"2024-04-05T13:59:21.983977Z","shell.execute_reply":"2024-04-05T13:59:21.989874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_imgs = prep_df('./food-101/meta/train.txt')\ntest_imgs = prep_df('./food-101/meta/test.txt')\n\ntrain_imgs.head(5)","metadata":{"papermill":{"duration":0.700727,"end_time":"2023-11-07T12:32:59.64035","exception":false,"start_time":"2023-11-07T12:32:58.939623","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T13:59:25.233954Z","iopub.execute_input":"2024-04-05T13:59:25.234289Z","iopub.status.idle":"2024-04-05T13:59:25.646001Z","shell.execute_reply.started":"2024-04-05T13:59:25.234263Z","shell.execute_reply":"2024-04-05T13:59:25.645105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 5))\n\nnum_rows = 3\nnum_cols = 8\n\n\nfor idx in range(num_rows * num_cols):\n    random_idx = np.random.randint(0, train_imgs.shape[0])\n    img = plt.imread(train_imgs.path.iloc[random_idx])\n\n    label = train_imgs.label.iloc[random_idx]\n\n    ax = plt.subplot(num_rows, num_cols, idx + 1)\n    plt.imshow(img)\n    plt.title(label)\n    plt.axis(\"off\")","metadata":{"papermill":{"duration":2.937209,"end_time":"2023-11-07T12:33:03.326735","exception":false,"start_time":"2023-11-07T12:33:00.389526","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T13:59:30.13434Z","iopub.execute_input":"2024-04-05T13:59:30.135159Z","iopub.status.idle":"2024-04-05T13:59:33.145848Z","shell.execute_reply.started":"2024-04-05T13:59:30.135127Z","shell.execute_reply":"2024-04-05T13:59:33.144803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data augmentation for training\ntrain_transforms = transforms.Compose([transforms.RandomRotation(30),\n                                       transforms.RandomResizedCrop(224),\n                                       transforms.RandomHorizontalFlip(),\n                                       torchvision.transforms.AutoAugment(torchvision.transforms.AutoAugmentPolicy.IMAGENET),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize([0.485, 0.456, 0.406],\n                                                            [0.229, 0.224, 0.225])])\n# Data augmentation for testing\ntest_transforms = transforms.Compose([transforms.Resize(255),\n                                      transforms.CenterCrop(224),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406],\n                                                           [0.229, 0.224, 0.225])])","metadata":{"papermill":{"duration":0.215806,"end_time":"2023-11-07T12:33:05.735849","exception":false,"start_time":"2023-11-07T12:33:05.520043","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T13:59:45.228298Z","iopub.execute_input":"2024-04-05T13:59:45.229138Z","iopub.status.idle":"2024-04-05T13:59:45.236138Z","shell.execute_reply.started":"2024-04-05T13:59:45.229104Z","shell.execute_reply":"2024-04-05T13:59:45.235256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Label_encoder:\n    def __init__(self, labels):\n        labels = list(set(labels))\n        self.labels = {label: idx for idx, label in enumerate(classes)}\n\n    def get_label(self, idx):\n        return list(self.labels.keys())[idx]\n\n    def get_idx(self, label):\n        return self.labels[label]\n\nencoder = Label_encoder(classes)\nfor i in range(20):\n    print(encoder.get_label(i), encoder.get_idx( encoder.get_label(i) ))","metadata":{"papermill":{"duration":0.172957,"end_time":"2023-11-07T12:33:06.423592","exception":false,"start_time":"2023-11-07T12:33:06.250635","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T13:59:49.869658Z","iopub.execute_input":"2024-04-05T13:59:49.87067Z","iopub.status.idle":"2024-04-05T13:59:49.877945Z","shell.execute_reply.started":"2024-04-05T13:59:49.870626Z","shell.execute_reply":"2024-04-05T13:59:49.877017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Food20(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe\n        self.transform = transform\n\n    def __len__(self):\n        return self.dataframe.shape[0]\n\n    def __getitem__(self, idx):\n        img_name = self.dataframe.path.iloc[idx]\n        image = Image.open(img_name)\n        if image.mode != 'RGB':\n            image = image.convert('RGB')\n        label = encoder.get_idx(self.dataframe.label.iloc[idx])\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label","metadata":{"papermill":{"duration":0.171262,"end_time":"2023-11-07T12:33:07.075662","exception":false,"start_time":"2023-11-07T12:33:06.9044","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T13:59:57.830307Z","iopub.execute_input":"2024-04-05T13:59:57.83069Z","iopub.status.idle":"2024-04-05T13:59:57.838114Z","shell.execute_reply.started":"2024-04-05T13:59:57.830656Z","shell.execute_reply":"2024-04-05T13:59:57.837168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = Food20(train_imgs, transform=train_transforms)\ntest_dataset = Food20(test_imgs, transform=test_transforms)","metadata":{"papermill":{"duration":0.193105,"end_time":"2023-11-07T12:33:07.746856","exception":false,"start_time":"2023-11-07T12:33:07.553751","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T14:00:03.069015Z","iopub.execute_input":"2024-04-05T14:00:03.06938Z","iopub.status.idle":"2024-04-05T14:00:03.073892Z","shell.execute_reply.started":"2024-04-05T14:00:03.069352Z","shell.execute_reply":"2024-04-05T14:00:03.07286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)","metadata":{"papermill":{"duration":0.173243,"end_time":"2023-11-07T12:33:08.419333","exception":false,"start_time":"2023-11-07T12:33:08.24609","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T14:00:06.428234Z","iopub.execute_input":"2024-04-05T14:00:06.428872Z","iopub.status.idle":"2024-04-05T14:00:06.433813Z","shell.execute_reply.started":"2024-04-05T14:00:06.42884Z","shell.execute_reply":"2024-04-05T14:00:06.432871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing the retrieval of a single image\nfor i in range(10):\n    image = train_dataset.__getitem__(i)\n    print(encoder.get_label(image[1]), image[0].shape)","metadata":{"papermill":{"duration":0.328711,"end_time":"2023-11-07T12:33:08.911848","exception":false,"start_time":"2023-11-07T12:33:08.583137","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T14:00:09.571644Z","iopub.execute_input":"2024-04-05T14:00:09.572003Z","iopub.status.idle":"2024-04-05T14:00:09.782087Z","shell.execute_reply.started":"2024-04-05T14:00:09.571975Z","shell.execute_reply":"2024-04-05T14:00:09.781186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights = models.DenseNet201_Weights.IMAGENET1K_V1\nmodel = models.densenet201(weights = weights)","metadata":{"papermill":{"duration":2.077198,"end_time":"2023-11-07T12:33:11.802331","exception":false,"start_time":"2023-11-07T12:33:09.725133","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T14:00:12.984866Z","iopub.execute_input":"2024-04-05T14:00:12.985223Z","iopub.status.idle":"2024-04-05T14:00:13.938393Z","shell.execute_reply.started":"2024-04-05T14:00:12.985194Z","shell.execute_reply":"2024-04-05T14:00:13.937452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Freeze parameters so we don't backprop through them\nfor param in model.parameters():\n    param.requires_grad = False","metadata":{"papermill":{"duration":0.172675,"end_time":"2023-11-07T12:33:12.136482","exception":false,"start_time":"2023-11-07T12:33:11.963807","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T14:00:21.485827Z","iopub.execute_input":"2024-04-05T14:00:21.486089Z","iopub.status.idle":"2024-04-05T14:00:21.504858Z","shell.execute_reply.started":"2024-04-05T14:00:21.486066Z","shell.execute_reply":"2024-04-05T14:00:21.503931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import requests as reqs\n\nurl = \"https://github.com/Prakhar998/Food-Classification/raw/master/food_classifier.pt\"  \nr = reqs.get(url, allow_redirects=True)\n\nopen(\"./food_classifier.pt\", \"wb\").write(r.content)","metadata":{"papermill":{"duration":6.040819,"end_time":"2023-11-07T12:33:18.661121","exception":false,"start_time":"2023-11-07T12:33:12.620302","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T14:00:24.518306Z","iopub.execute_input":"2024-04-05T14:00:24.51922Z","iopub.status.idle":"2024-04-05T14:00:27.138401Z","shell.execute_reply.started":"2024-04-05T14:00:24.519183Z","shell.execute_reply":"2024-04-05T14:00:27.137402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = \"./food_classifier.pt\"\nclassifier = nn.Sequential(\n    nn.Linear(1920,1024),\n    nn.LeakyReLU(),\n    nn.Linear(1024,101),\n)\n\nmodel.classifier = classifier\nmodel.load_state_dict(torch.load(checkpoint_path,map_location='cpu'),strict=False)\n\nmodel.to(device)","metadata":{"papermill":{"duration":3.306916,"end_time":"2023-11-07T12:33:22.475329","exception":false,"start_time":"2023-11-07T12:33:19.168413","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T14:00:31.804085Z","iopub.execute_input":"2024-04-05T14:00:31.804672Z","iopub.status.idle":"2024-04-05T14:00:31.980011Z","shell.execute_reply.started":"2024-04-05T14:00:31.804639Z","shell.execute_reply":"2024-04-05T14:00:31.979099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hyper parameters\nnum_epochs = 3\n\n# loss\nloss_fn = nn.CrossEntropyLoss()\n\n# all parameters are being optimized\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=[0.9, 0.999])\n\nmodel = model.to(device)","metadata":{"papermill":{"duration":0.172967,"end_time":"2023-11-07T12:33:22.81324","exception":false,"start_time":"2023-11-07T12:33:22.640273","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T14:00:51.765355Z","iopub.execute_input":"2024-04-05T14:00:51.765705Z","iopub.status.idle":"2024-04-05T14:00:51.784342Z","shell.execute_reply.started":"2024-04-05T14:00:51.765678Z","shell.execute_reply":"2024-04-05T14:00:51.783622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_step(model: torch.nn.Module,\n               dataloader: torch.utils.data.DataLoader,\n               loss_fn: torch.nn.Module,\n               optimizer: torch.optim.Optimizer,\n               device: torch.device):\n  # Put model in train mode\n  model.train()\n\n  # Setup train loss and train accuracy values\n  train_loss, train_acc = 0, 0\n\n  print(\"--> Training Progress\")\n  # Loop through data loader data batches\n  for batch, (X, y) in enumerate(tqdm(dataloader)):\n      # Send data to target device\n      images, labels = X.to(device), y.to(device)\n\n      # 1. Forward pass\n      y_pred = model(images)\n\n      # 2. Calculate  and accumulate loss\n      loss = loss_fn(y_pred, labels)\n      train_loss += loss.item()\n\n      # 3. Optimizer zero grad\n      optimizer.zero_grad()\n\n      # 4. Loss backward\n      loss.backward()\n\n      # 5. Optimizer step\n      optimizer.step()\n\n      # Calculate and accumulate accuracy metric across all batches\n      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n      train_acc += (y_pred_class == labels).sum().item()/len(y_pred)\n\n  # Adjust metrics to get average loss and accuracy per batch\n  train_loss = train_loss / len(dataloader)\n  train_acc = train_acc / len(dataloader)\n  return train_loss, train_acc","metadata":{"papermill":{"duration":0.182547,"end_time":"2023-11-07T12:33:23.908226","exception":false,"start_time":"2023-11-07T12:33:23.725679","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T14:00:55.695793Z","iopub.execute_input":"2024-04-05T14:00:55.696127Z","iopub.status.idle":"2024-04-05T14:00:55.705388Z","shell.execute_reply.started":"2024-04-05T14:00:55.696104Z","shell.execute_reply":"2024-04-05T14:00:55.704484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_step(model: torch.nn.Module,\n              dataloader: torch.utils.data.DataLoader,\n              loss_fn: torch.nn.Module,\n              device: torch.device):\n  # Put model in eval mode\n  model.eval()\n\n  # Setup test loss and test accuracy values\n  test_loss, test_acc = 0, 0\n\n  # Turn on inference context manager\n  with torch.inference_mode():\n      print(\"--> Testing Progress\")\n      # Loop through DataLoader batches\n      for batch, (X, y) in enumerate(tqdm(dataloader)):\n          # Send data to target device\n          images, labels = X.to(device), y.to(device)\n\n          # 1. Forward pass\n          test_pred_logits = model(images)\n\n          # 2. Calculate and accumulate loss\n          loss = loss_fn(test_pred_logits, labels)\n          test_loss += loss.item()\n\n          # Calculate and accumulate accuracy\n          test_pred_labels = torch.argmax(torch.softmax(test_pred_logits, dim=1), dim=1)\n\n          test_acc += ((test_pred_labels == labels).sum().item()/len(test_pred_labels))\n\n  # Adjust metrics to get average loss and accuracy per batch\n  test_loss = test_loss / len(dataloader)\n  test_acc = test_acc / len(dataloader)\n  return test_loss, test_acc","metadata":{"papermill":{"duration":0.18096,"end_time":"2023-11-07T12:33:24.260136","exception":false,"start_time":"2023-11-07T12:33:24.079176","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T14:00:59.905743Z","iopub.execute_input":"2024-04-05T14:00:59.906374Z","iopub.status.idle":"2024-04-05T14:00:59.91475Z","shell.execute_reply.started":"2024-04-05T14:00:59.906343Z","shell.execute_reply":"2024-04-05T14:00:59.913763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model: torch.nn.Module,\n          train_dataloader: torch.utils.data.DataLoader,\n          test_dataloader: torch.utils.data.DataLoader,\n          optimizer: torch.optim.Optimizer,\n          loss_fn: torch.nn.Module,\n          epochs: int,\n          device: torch.device):\n  # Create empty results dictionary\n  history = {\n      \"train_loss\": [],\n      \"train_acc\": [],\n      \"test_loss\": [],\n      \"test_acc\": [],\n      'best train acc': (0, 0),\n      \"best_model\": dict()\n  }\n\n  # Loop through training and testing steps for a number of epochs\n  for epoch in range(epochs):\n      print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n\n      train_loss, train_acc = train_step(model=model,\n                                          dataloader=train_dataloader,\n                                          loss_fn=loss_fn,\n                                          optimizer=optimizer,\n                                          device=device)\n      test_loss, test_acc = test_step(model=model,\n          dataloader=test_dataloader,\n          loss_fn=loss_fn,\n          device=device)\n\n      # Print out what's happening\n      print(\n          f\"Epoch: {epoch+1} | \"\n          f\"train_loss: {train_loss:.4f} | \"\n          f\"train_acc: {train_acc:.4f} | \"\n          f\"test_loss: {test_loss:.4f} | \"\n          f\"test_acc: {test_acc:.4f}\"\n          f\"\\n\\n=============================\\n\"\n      )\n\n      # Update results dictionary\n      history[\"train_loss\"].append(train_loss)\n      history[\"train_acc\"].append(train_acc)\n      history[\"test_loss\"].append(test_loss)\n      history[\"test_acc\"].append(test_acc)\n      if test_loss < history[\"test_acc\"][len(history[\"test_acc\"]) - 1]:\n          history[\"best_model\"] = model.state_dict()\n\n      if test_acc > 0.95:\n         break\n\n  # Return the filled results at the end of the epochs\n  return model, history","metadata":{"papermill":{"duration":0.224207,"end_time":"2023-11-07T12:33:24.989179","exception":false,"start_time":"2023-11-07T12:33:24.764972","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T14:01:04.260636Z","iopub.execute_input":"2024-04-05T14:01:04.261336Z","iopub.status.idle":"2024-04-05T14:01:04.271449Z","shell.execute_reply.started":"2024-04-05T14:01:04.261306Z","shell.execute_reply":"2024-04-05T14:01:04.270428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, history = train(model, train_loader, test_loader, optimizer, loss_fn, num_epochs, device)","metadata":{"papermill":{"duration":2502.779374,"end_time":"2023-11-07T13:15:07.935786","exception":false,"start_time":"2023-11-07T12:33:25.156412","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T14:01:10.971877Z","iopub.execute_input":"2024-04-05T14:01:10.972729Z","iopub.status.idle":"2024-04-05T14:56:56.204064Z","shell.execute_reply.started":"2024-04-05T14:01:10.972696Z","shell.execute_reply":"2024-04-05T14:56:56.203101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, dataloader):\n\n  random = np.random.randint(0, len(dataloader))\n\n  with torch.no_grad():\n    model.eval()\n    n_correct = 0\n    n_samples = 0\n\n    for images, labels in tqdm(dataloader):\n      images = images.to(device)\n      labels = labels.to(device)\n\n      outputs = model(images)\n\n      preds = torch.argmax(torch.softmax(outputs, 1), 1)\n\n      # Converting this problem to a problem with 21 clases only\n      preds = np.array([pred.cpu() if pred < 20 else 20 for pred in preds])\n      labels = np.array([label.cpu() if label < 20 else 20 for label in labels])\n\n      n_samples += labels.shape[0]\n      n_correct += (preds==labels).sum().item()\n\n    acc = 100.0 * n_correct / n_samples\n    print(acc)","metadata":{"papermill":{"duration":0.352878,"end_time":"2023-11-07T13:15:13.561243","exception":false,"start_time":"2023-11-07T13:15:13.208365","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T14:57:19.00084Z","iopub.execute_input":"2024-04-05T14:57:19.001745Z","iopub.status.idle":"2024-04-05T14:57:19.009476Z","shell.execute_reply.started":"2024-04-05T14:57:19.001706Z","shell.execute_reply":"2024-04-05T14:57:19.008567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(model,test_loader)","metadata":{"papermill":{"duration":183.597182,"end_time":"2023-11-07T13:18:17.500395","exception":false,"start_time":"2023-11-07T13:15:13.903213","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T14:57:23.702694Z","iopub.execute_input":"2024-04-05T14:57:23.703071Z","iopub.status.idle":"2024-04-05T15:01:28.372069Z","shell.execute_reply.started":"2024-04-05T14:57:23.703044Z","shell.execute_reply":"2024-04-05T15:01:28.371037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Label_encoder_21:\n    def __init__(self, labels):\n        labels = list(set(labels))\n        self.labels = {label: idx for idx, label in enumerate(labels)}\n\n    def get_label(self, idx):\n        return list(self.labels.keys())[idx]\n\n    def get_idx(self, label):\n        return self.labels[label]\n\nencoder_21 = Label_encoder(classes_21)\nencoder_21.get_label(0), encoder.get_idx( encoder_21.get_label(0) )","metadata":{"papermill":{"duration":0.428221,"end_time":"2023-11-07T13:18:19.060855","exception":false,"start_time":"2023-11-07T13:18:18.632634","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T15:23:30.340263Z","iopub.execute_input":"2024-04-05T15:23:30.340961Z","iopub.status.idle":"2024-04-05T15:23:30.349666Z","shell.execute_reply.started":"2024-04-05T15:23:30.340926Z","shell.execute_reply":"2024-04-05T15:23:30.348731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This line of code saves the best model's state dictionary (or parameters) from the training history to a file named solution.pth.\ntorch.save(history['best_model'], \"./solution.pth\")","metadata":{"papermill":{"duration":0.588128,"end_time":"2023-11-07T13:18:26.535338","exception":false,"start_time":"2023-11-07T13:18:25.94721","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T15:23:35.249648Z","iopub.execute_input":"2024-04-05T15:23:35.249972Z","iopub.status.idle":"2024-04-05T15:23:35.520197Z","shell.execute_reply.started":"2024-04-05T15:23:35.249948Z","shell.execute_reply":"2024-04-05T15:23:35.51909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nif os.path.exists(\"./solution.pth\"):\n    print(\"solution.pth exists in the current directory.\")\nelse:\n    print(\"solution.pth does not exist in the current directory.\")\n","metadata":{"papermill":{"duration":0.382617,"end_time":"2023-11-07T13:18:27.290987","exception":false,"start_time":"2023-11-07T13:18:26.90837","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-05T15:23:39.271152Z","iopub.execute_input":"2024-04-05T15:23:39.272031Z","iopub.status.idle":"2024-04-05T15:23:39.276992Z","shell.execute_reply.started":"2024-04-05T15:23:39.272Z","shell.execute_reply":"2024-04-05T15:23:39.276082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'saved_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-04-05T15:23:43.291751Z","iopub.execute_input":"2024-04-05T15:23:43.292601Z","iopub.status.idle":"2024-04-05T15:23:43.615053Z","shell.execute_reply.started":"2024-04-05T15:23:43.292565Z","shell.execute_reply":"2024-04-05T15:23:43.614067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom PIL import Image\nfrom torchvision import transforms\n\ndef classify_image(image_path, model, label_encoder, device):\n    # Load and preprocess the input image\n    image = Image.open(image_path)\n    preprocess = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n    image_tensor = preprocess(image).unsqueeze(0).to(device)\n\n    # Perform prediction\n    with torch.no_grad():\n        model.eval()\n        output = model(image_tensor)\n\n    # Get predicted class index\n    _, predicted_idx = torch.max(output, 1)\n    predicted_idx = predicted_idx.item()\n\n    # Map index to class name\n    predicted_label = label_encoder.get_label(predicted_idx)\n\n    return predicted_label\n\n# Load the saved model and label encoder\nmodel = models.densenet201(weights=None)\nclassifier = nn.Sequential(\n    nn.Linear(1920, 1024),\n    nn.LeakyReLU(),\n    nn.Linear(1024, 101),\n)\nmodel.classifier = classifier\nmodel.load_state_dict(torch.load(\"solution.pth\", map_location=device))\nmodel.to(device)\nmodel.eval()\n\nlabel_encoder = Label_encoder(classes)\n\n\n# Classify an image\nimage_path = \"/kaggle/working/food-101/images/chicken_curry/1208906.jpg\"  # Replace with the path to your image\npredicted_label = classify_image(image_path, model, label_encoder, device)\nprint(\"Predicted Label:\", predicted_label)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T15:36:07.67131Z","iopub.execute_input":"2024-04-05T15:36:07.671619Z","iopub.status.idle":"2024-04-05T15:36:08.393451Z","shell.execute_reply.started":"2024-04-05T15:36:07.671585Z","shell.execute_reply":"2024-04-05T15:36:08.392469Z"},"trusted":true},"execution_count":null,"outputs":[]}]}